{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    print(\"Reading file\", filename)\n",
    "    for progress in range(0, 100, 25):\n",
    "        print(f\"Read {progress}%\")\n",
    "        sleep(.5)\n",
    "    print(\"Reading completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_computation():\n",
    "    print(\"Computation started\")\n",
    "    for progress in range(0, 100, 25):\n",
    "        print(f\"Computed {progress}%\")\n",
    "        sleep(.5)\n",
    "    print(\"Computation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file a.fits\n",
      "Read 0%\n",
      "Read 25%\n",
      "Read 50%\n",
      "Read 75%\n",
      "Reading completed\n",
      "CPU times: user 2 ms, sys: 1 ms, total: 3 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%time read_data(\"a.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation started\n",
      "Computed 0%\n",
      "Computed 25%\n",
      "Computed 50%\n",
      "Computed 75%\n",
      "Computation completed\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%time perform_computation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = dask.delayed(read_data)(\"a.fits\")\n",
    "t2 = dask.delayed(perform_computation)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation startedReading file a.fits\n",
      "Read 0%\n",
      "\n",
      "Computed 0%\n",
      "Read 25%\n",
      "Computed 25%\n",
      "Read 50%\n",
      "Computed 50%\n",
      "Read 75%\n",
      "Computed 75%\n",
      "Reading completed\n",
      "Computation completed\n",
      "CPU times: user 7 ms, sys: 5 ms, total: 12 ms\n",
      "Wall time: 2.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dask.compute(t1, t2, scheduler=\"threading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat many times, see if you can get different orders of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The get= keyword has been removed.\n\nPlease use the scheduler= keyword instead with the name of\nthe desired scheduler like 'threads' or 'processes'\n\n    x.compute(scheduler='single-threaded')\n    x.compute(scheduler='threads')\n    x.compute(scheduler='processes')\n\nor with a function that takes the graph and keys\n\n    x.compute(scheduler=my_scheduler_function)\n\nor with a Dask client\n\n    x.compute(scheduler=client)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     schedule = get_scheduler(scheduler=kwargs.pop('scheduler', None),\n\u001b[1;32m    392\u001b[0m                              \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                              get=kwargs.pop('get', None))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections_to_dsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mget_scheduler\u001b[0;34m(get, scheduler, collections, cls)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \"\"\"\n\u001b[1;32m    862\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_err_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The get= keyword has been removed.\n\nPlease use the scheduler= keyword instead with the name of\nthe desired scheduler like 'threads' or 'processes'\n\n    x.compute(scheduler='single-threaded')\n    x.compute(scheduler='threads')\n    x.compute(scheduler='processes')\n\nor with a function that takes the graph and keys\n\n    x.compute(scheduler=my_scheduler_function)\n\nor with a Dask client\n\n    x.compute(scheduler=client)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dask.compute(t1, t2, scheduler=\"processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
